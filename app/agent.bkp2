"""
Author: Yara
"""
from __future__ import annotations
import asyncio, json, os
from typing import Any, Dict, Optional

from google import genai
from google.genai import types as genai_types
from app.mcp_client import CarClient

from app.prompts.car_agent_prompts import build_extraction_prompt, GATEKEEPER_INSTRUCTION
from app.prompts.car_agent_texts import (
    KEY_ORDER,
    RESPONSE_SCHEMA,
    PROCEED_SCHEMA,
    QUESTIONS_MAP,
    INTRO_HEADER,
    INTRO_EXAMPLES,
    EXTRA_CONSTRAINTS_PROMPT,
)

class TerminalCarAgent:
    def __init__(self) -> None:
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise SystemExit("Requires environment variable GEMINI_API_KEY.")
        self.client = genai.Client(api_key=api_key)
        self.model_name = "gemini-2.0-flash"  # free-tier-elegible

        self.filters: Dict[str, Any] = {
            "make": None, "model": None, "fuel": None, "color": None,
            "year_min": None, "price_max": None, "mileage_max": None,
            "is_new": None, "is_automatic": None,
            "has_air_conditioning": None, "has_bt_radio": None,
            "has_charger_plug": None, "is_armored": None,
        }

    def apply_extracted_filters(self, parsed: Dict[str, Any]) -> None:
        for k, v in (parsed or {}).items():
            if k in ("make","model","fuel","color"):
                self.filters[k] = "" if v is None else str(v)
            elif k in ("year_min","price_max","mileage_max"):
                self.filters[k] = 0 if v is None else int(v)
            elif k in ("is_new","is_automatic","has_air_conditioning","has_bt_radio",
                       "has_charger_plug","is_armored"):
                if v is not None:
                    self.filters[k] = bool(v)

    def relax_filters(self, runs: int) -> Dict[str, Any]:
        relaxed = dict(self.filters)
        if runs > 1:
            relaxed["make"] = ""
            return relaxed
        relaxed["model"] = ""
        y = relaxed.get("year_min")
        if isinstance(y, int) and y and y > 1980:
            relaxed["year_min"] = max(1980, y - 3)
        p = relaxed.get("price_max")
        if isinstance(p, int) and p:
            relaxed["price_max"] = int(p * 1.25)
        return relaxed

    def _current_key(self) -> Optional[str]:
        for k in KEY_ORDER:
            if self.filters.get(k) is None:
                return k
        return None

    def _build_extraction_prompt(self, user_text: str) -> str:
        return build_extraction_prompt(user_text, self._current_key())

    def next_question(self) -> Optional[str]:
        for key in KEY_ORDER:
            if self.filters.get(key) is None:
                return QUESTIONS_MAP[key]
        return None

    def llm_wants_to_proceed(self, latest_user_text: str) -> bool:
        if self.next_question() is not None:
            return False

        full = f"{GATEKEEPER_INSTRUCTION}\n\nUser input:\n{latest_user_text}"
        resp = self.client.models.generate_content(
            model=self.model_name,
            contents=[genai_types.Content(
                role="user",
                parts=[genai_types.Part.from_text(full)]
            )],
            config=genai_types.GenerateContentConfig(
                temperature=0,
                response_mime_type="application/json",
                response_schema=PROCEED_SCHEMA,
            ),
        )
        raw = (getattr(resp, "text", None) or "")
        try:
            parsed = json.loads(raw)
        except Exception:
            parsed = raw.strip().strip('"')
        return str(parsed).strip().upper() == "PROCEED"

    async def run(self) -> None:
        print(INTRO_HEADER)
        print(INTRO_EXAMPLES)

        q = self.next_question()
        if q: print(q)

        while True:
            text = input("> ").strip()
            if not text:
                if (q := self.next_question()): print(q)
                continue

            low = text.lower()
            if low in {"exit","quit","sair"}:
                print("Bye."); return
            if self.llm_wants_to_proceed(text):
                break

            full = self._build_extraction_prompt(text)
            resp = self.client.models.generate_content(
                model=self.model_name,
                contents=[genai_types.Content(
                    role="user",
                    parts=[genai_types.Part.from_text(full)]
                )],
                config=genai_types.GenerateContentConfig(
                    temperature=0,
                    response_mime_type="application/json",
                    response_schema=RESPONSE_SCHEMA,
                ),
            )
            args = json.loads((getattr(resp, "text", None) or "{}"))
            self.apply_extracted_filters(args)

            if self.next_question() is not None:
                if self.llm_wants_to_proceed(text):
                    break

            if (q := self.next_question()):
                print(q)
            else:
                break

        print(EXTRA_CONSTRAINTS_PROMPT)
        while True:
            t = input("> ").strip()
            if self.llm_wants_to_proceed(t):
                break

            full2 = self._build_extraction_prompt(t)
            resp = self.client.models.generate_content(
                model=self.model_name,
                contents=[genai_types.Content(
                    role="user",
                    parts=[genai_types.Part.from_text(full2)]
                )],
                config=genai_types.GenerateContentConfig(
                    temperature=0,
                    response_mime_type="application/json",
                    response_schema=RESPONSE_SCHEMA,
                ),
            )
            args = json.loads((getattr(resp, "text", None) or "{}"))
            self.apply_extracted_filters(args)

        c = CarClient()
        await c.initialize()
        try:
            rows = await self.db_query(c, self.filters)

            if not rows:
                print("No exact match. Looking for similar results...")
                nf = self.relax_filters(runs=1)
                rows = await self.db_query(c, nf)

            if not rows or len(rows) < 3:
                print("Querying additional similar cars...")
                nf = self.relax_filters(runs=2)
                more = await self.db_query(c, nf)
                if more:
                    rows = (rows or []) + more
        finally:
            await c.close()

        if not rows:
            print("Sorry, at the moment we don't have cars available that matches your search. Please try again")
            return

        print("\nResults:")
        for i, car in enumerate(rows, 1):
            make = car.get("make"); model = car.get("model")
            year = car.get("year"); color = car.get("color")
            mileage = car.get("mileage"); price = car.get("dollar_price")
            km = f"{int(mileage):,}".replace(",", ".") if isinstance(mileage,(int,float)) else str(mileage)
            pr = "US$ " + f"{int(price):,}".replace(",", ".") if isinstance(price,(int,float)) else str(price)
            print(f"- {i}. {make} {model} {year}, {color}, {km} km, {pr}")

        print("\nType 'new' to start another search or 'exit' to quit.")
        if input("> ").strip().lower() in {"new","again","y","yes"}:
            self.__init__(); await self.run()

    async def db_query(self, c: CarClient, query_filters: Dict[str, Any], limit: int = 50):
        """
        Consulta o MCP/DB com os filtros fornecidos e fecha o cliente corretamente.
        nf: dict com make, fuel, year_min, price_max
        """
        return await c.search_cars(
            make=query_filters.get("make"),
            fuel=query_filters.get("fuel"),
            year_min=query_filters.get("year_min"),
            price_max=query_filters.get("price_max"),
            limit=limit,
        )

if __name__ == "__main__":
    asyncio.run(TerminalCarAgent().run())
